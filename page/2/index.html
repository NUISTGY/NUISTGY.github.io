<!DOCTYPE html><html lang="zh-Hans"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Do what you want to do !"><meta name="keywords" content><meta name="author" content="GeYu"><meta name="copyright" content="GeYu"><title>Do not go gentle into that good night. | Ming's Blog</title><link rel="shortcut icon" href="/favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="author-info"><div class="author-info__avatar text-center"><img src="http://m.qpic.cn/psb?/V14eJTFY0iNxUQ/uTIFlXdjAcjw501eJjHoGiEApfgXVxJjMHclu5EBShE!/b/dLYAAAAAAAAA&amp;bo=zAHMAQAAAAARBzA!&amp;rf=viewer_4&amp;t=5"></div><div class="author-info__name text-center">GeYu</div><div class="author-info__description text-center">Do what you want to do !</div><div class="follow-button"><a href="https://github.com/NUISTGY">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">30</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">18</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">7</span></a></div></div></div><nav id="nav" style="background-image: url(http://a1.qpic.cn/psb?/V14eJTFY137vJk/i09jWCouwvJawAtXHQ7*VnrLqAAatJunqVGTTh85alU!/b/dNwAAAAAAAAA&amp;ek=1&amp;kp=1&amp;pt=0&amp;bo=HAtABgAPcAgRGQg!&amp;tl=3&amp;vuin=1328447669&amp;tm=1562745600&amp;sce=60-2-2&amp;rf=viewer_4&amp;t=5)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Ming's Blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">About</a></span></div><div id="site-info"><div id="site-title">Ming's Blog</div><div id="site-sub-title">Do not go gentle into that good night.</div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2020/01/20/Java学习之路(3)/">Java学习之路--java常量</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-01-20</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Java/">Java</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/编程/">编程</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/学习/">学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Java/">Java</a></span><div class="content"><script src="/assets/js/APlayer.min.js"> </script><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Java常量</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> 葛宇</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">package</span> 数据类型和运算符;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestConstant</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">	  <span class="comment">//age和name都是变量，数字18、20和字符串“GeYu”“GEYU”是字面常量</span></span><br><span class="line">		<span class="keyword">int</span> age = <span class="number">18</span>;</span><br><span class="line">		age = <span class="number">20</span>;</span><br><span class="line">		String name = <span class="string">"GeYu"</span>;</span><br><span class="line">		name = <span class="string">"GEYU"</span>;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">final</span> <span class="keyword">double</span> PI = <span class="number">3.14</span>;</span><br><span class="line">	             <span class="comment">//PI++; 报错，final将PI定义为了符号常量</span></span><br><span class="line">		</span><br><span class="line">		<span class="comment">/*</span></span><br><span class="line"><span class="comment">		 * 命名规范</span></span><br><span class="line"><span class="comment">		 * 常量：全部大写，可配合下划线：MAX_VALUE</span></span><br><span class="line"><span class="comment">		 * 类名：首字母大写，驼峰原则：HelloWorld、FatherClass</span></span><br><span class="line"><span class="comment">		 * 类成员变量、类方法：首字母小写，驼峰原则：monthSalary、getSalary()</span></span><br><span class="line"><span class="comment">		 */</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/01/20/Java学习之路(2)/">Java学习之路--java标识符</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-01-20</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Java/">Java</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/编程/">编程</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/学习/">学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Java/">Java</a></span><div class="content"><script src="/assets/js/APlayer.min.js"> </script><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Java标识符用法</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> 葛宇</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">package</span> 数据类型和运算符;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestIdentifer</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">int</span> a123 = <span class="number">1</span>;</span><br><span class="line">                             <span class="comment">//int 123a = 2; 数字不能打头</span></span><br><span class="line">		<span class="keyword">int</span> $abc = <span class="number">3</span>;</span><br><span class="line">		<span class="keyword">int</span> _abc = <span class="number">4</span>; </span><br><span class="line">		<span class="keyword">int</span>  年龄 = <span class="number">18</span>; <span class="comment">//Java支持中文变量但不建议使用</span></span><br><span class="line">	             <span class="comment">//int public =5;   关键字不能作为变量去使用</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/01/20/Java学习之路(1)/">Java学习之路--java注释</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-01-20</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Java/">Java</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/编程/">编程</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/学习/">学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/Java/">Java</a></span><div class="content"><script src="/assets/js/APlayer.min.js"> </script><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Java注释</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> 葛宇</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">package</span> 数据类型和运算符; <span class="comment">//这是单行注释</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestComment</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args <span class="comment">/*多行注释也可用作行内注释*/</span>)</span> </span>&#123;</span><br><span class="line">		System.out.println(<span class="string">"Hello World !"</span>); </span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">	 * 多行注释</span></span><br><span class="line"><span class="comment">	 * 多行注释</span></span><br><span class="line"><span class="comment">	 * 多行注释</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/10/24/试玩YOLOv3多目标检测/">试玩YOLOv3多目标检测</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-10-24</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/深度学习/">深度学习</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/深度学习/">深度学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/图像处理/">图像处理</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/目标检测/">目标检测</a></span><div class="content"><script src="/assets/js/APlayer.min.js"> </script><h1 id="YOLOv3简介"><a href="#YOLOv3简介" class="headerlink" title="YOLOv3简介"></a>YOLOv3简介</h1><p><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/cn5iP7sLblgU954coh9a6gIHqT7V1JFUDxut7s8rrZA!/b/dFABAAAAAAAA&bo=UQTZAlEE2QIDCSw!&rf=viewer_4&t=5" alt="被抓拍于明德楼（卑微.jpg"></p>
<p><a href="https://pjreddie.com/darknet/yolo/" target="_blank" rel="noopener">官网链接</a><br><a href="https://pjreddie.com/media/files/papers/YOLOv3.pdf" target="_blank" rel="noopener">论文链接</a></p>
<h1 id="运行环境搭建"><a href="#运行环境搭建" class="headerlink" title="运行环境搭建"></a>运行环境搭建</h1><p>首先下载源码：<br><strong>源码：</strong> <a href="https://github.com/NUISTGY/TensorFlow2.0-Examples/tree/master/4-Object_Detection/YOLOV3" target="_blank" rel="noopener">https://github.com/NUISTGY/TensorFlow2.0-Examples/tree/master/4-Object_Detection/YOLOV3</a></p>
<p>接着安装依赖库和训练好的权重：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ pip3 install -r ./docs/requirements.txt</span><br><span class="line">$ wget https://pjreddie.com/media/files/yolov3.weights</span><br></pre></td></tr></table></figure>

<p>将权重文件置于源码文件夹目录下即可。</p>
<h1 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h1><p>前面已经完成了所有的准备公作，运行以下命令即可进行目标检测：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ python image_demo.py</span><br><span class="line">$ python video_demo.py # if use camera, set video_path = 0</span><br></pre></td></tr></table></figure>

<p><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/ZnqD2Ee*mTkaYWSLce8mN3fD4xPiZfCp1th4XNqARKM!/b/dIMAAAAAAAAA&bo=SAWEAwAAAAARB*o!&rf=viewer_4&t=5" alt="运行python image_demo.py的结果"></p>
<h1 id="尝试检测自己的图片或视频"><a href="#尝试检测自己的图片或视频" class="headerlink" title="尝试检测自己的图片或视频"></a>尝试检测自己的图片或视频</h1><p>想要识别自己的图片只需要做很小的改动即可。<br>打开<code>image_demo.py</code>:<br><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/Oe6YiqYx*h7Pa3eV1DvdMnunRkuVBMKhYEjXqmowPQM!/b/dL4AAAAAAAAA&bo=RgOKAAAAAAADB.0!&rf=viewer_4&t=5" alt><br>将22行image_path改为自己图片的地址即可，视频目标检测同理。</p>
<p>最后再贴一张目标比较多的照片：<br><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/eapwWj9E8AcZWp4HiBPEm*Lc9ANUi6eXT49kk7aVGas!/b/dIQAAAAAAAAA&bo=OgQPAjoEDwIDCSw!&rf=viewer_4&t=5" alt></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/08/24/行人重识别代码实战（二）/">行人重识别代码实战（二）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-08-24</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/深度学习/">深度学习</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/行人重识别/">行人重识别</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/深度学习/">深度学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/图像处理/">图像处理</a></span><div class="content"><script src="/assets/js/APlayer.min.js"> </script><h1 id="代码描述"><a href="#代码描述" class="headerlink" title="代码描述"></a><strong>代码描述</strong></h1><p><strong>代码来源：</strong> <a href="https://github.com/layumi/Person_reID_baseline_pytorch" target="_blank" rel="noopener">https://github.com/layumi/Person_reID_baseline_pytorch</a></p>
<p><code>详细信息可见README.md</code></p>
<p>这次研究的是<code>model.py</code>原理是利用和修改预训练模型，代码原作者使用的是<strong>ImageNet</strong>预训练网络。</p>
<p>pytorch里引入方式如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models</span><br><span class="line">model =models.resnet50(pretrained = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>通过<code>print（model）</code>查看网络结构：<br><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/8MG9.hHNVHEStAe57dJObL680lUBAxhdtq2g*C0Z7R8!/b/dL8AAAAAAAAA&bo=DAZ3AgAAAAADB10!&rf=viewer_4&t=5" alt></p>
<p>实际使用时要做修改。考虑到Market1501训练集中有751个不同的人，所以要改变模型来训练Reid的分类器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define the ResNet50-based Model</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ft_net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, class_num, droprate=<span class="number">0.5</span>, stride=<span class="number">2</span>)</span>:</span></span><br><span class="line">        super(ft_net, self).__init__()</span><br><span class="line">        model_ft = models.resnet50(pretrained=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># avg pooling to global pooling</span></span><br><span class="line">        <span class="keyword">if</span> stride == <span class="number">1</span>:</span><br><span class="line">            model_ft.layer4[<span class="number">0</span>].downsample[<span class="number">0</span>].stride = (<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">            model_ft.layer4[<span class="number">0</span>].conv2.stride = (<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">        model_ft.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">        self.model = model_ft</span><br><span class="line">        self.classifier = ClassBlock(<span class="number">2048</span>, class_num, droprate)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.model.conv1(x)</span><br><span class="line">        x = self.model.bn1(x)</span><br><span class="line">        x = self.model.relu(x)</span><br><span class="line">        x = self.model.maxpool(x)</span><br><span class="line">        x = self.model.layer1(x)</span><br><span class="line">        x = self.model.layer2(x)</span><br><span class="line">        x = self.model.layer3(x)</span><br><span class="line">        x = self.model.layer4(x)</span><br><span class="line">        x = self.model.avgpool(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), x.size(<span class="number">1</span>))</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<p>更多细节在model.py中，里面还包含了其他的预训练模型以及对应的修改方法。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/08/24/行人重识别代码实战（三）/">行人重识别代码实战（三）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-08-24</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/深度学习/">深度学习</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/行人重识别/">行人重识别</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/深度学习/">深度学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/图像处理/">图像处理</a></span><div class="content"><script src="/assets/js/APlayer.min.js"> </script><h1 id="代码描述"><a href="#代码描述" class="headerlink" title="代码描述"></a><strong>代码描述</strong></h1><p><strong>代码来源：</strong> <a href="https://github.com/layumi/Person_reID_baseline_pytorch" target="_blank" rel="noopener">https://github.com/layumi/Person_reID_baseline_pytorch</a></p>
<p><code>详细信息可见README.md</code></p>
<p>准备好了训练数据和网络结构，下面就可以训练了：</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">python train.py --gpu_ids <span class="number">0</span> --name ft_ResNet50 --train_all --batchsize <span class="number">32</span>  --data_dir your_data_path</span><br><span class="line">--gpu_ids which gpu to run.</span><br><span class="line">--name the name of the model.</span><br><span class="line">--data_dir the <span class="built_in">path</span> of the training data.</span><br><span class="line">--train_all using all images to train.</span><br><span class="line">--batchsize batch size.</span><br><span class="line">--erasing_p random erasing probability.</span><br></pre></td></tr></table></figure>

<p>这里探究一下<code>train.py</code>中都做了些什么。<br>首先是读取数据和label。这里使用了<code>torch.utils.data.DataLoader</code>, 可以获得两个迭代器<code>dataloaders[&#39;train&#39;]</code> and <code>dataloaders[&#39;val&#39;]</code> 来读数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">image_datasets = &#123;&#125;</span><br><span class="line">image_datasets[<span class="string">'train'</span>] = datasets.ImageFolder(os.path.join(data_dir, <span class="string">'train'</span>),</span><br><span class="line">                                         data_transforms[<span class="string">'train'</span>])</span><br><span class="line">image_datasets[<span class="string">'val'</span>] = datasets.ImageFolder(os.path.join(data_dir, <span class="string">'val'</span>),</span><br><span class="line">                                         data_transforms[<span class="string">'val'</span>])</span><br><span class="line"></span><br><span class="line">dataloaders = &#123;x: torch.utils.data.DataLoader(image_datasets[x], batch_size=opt.batchsize,</span><br><span class="line">                                            shuffle=<span class="literal">True</span>, num_workers=<span class="number">8</span>) <span class="comment"># 8 workers may work faster</span></span><br><span class="line">             <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">'train'</span>, <span class="string">'val'</span>]&#125;</span><br><span class="line">dataset_sizes = &#123;x: len(image_datasets[x]) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">'train'</span>, <span class="string">'val'</span>]&#125;</span><br></pre></td></tr></table></figure>

<p>以下则是主要的代码来训练模型，一共只有20行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Iterate over data.</span></span><br><span class="line">           <span class="keyword">for</span> data <span class="keyword">in</span> dataloaders[phase]:</span><br><span class="line">               <span class="comment"># get a batch of inputs</span></span><br><span class="line">               inputs, labels = data</span><br><span class="line">               now_batch_size,c,h,w = inputs.shape</span><br><span class="line">               <span class="keyword">if</span> now_batch_size&lt;opt.batchsize: <span class="comment"># skip the last batch</span></span><br><span class="line">                   <span class="keyword">continue</span></span><br><span class="line">               <span class="comment"># print(inputs.shape)</span></span><br><span class="line">               <span class="comment"># wrap them in Variable, if gpu is used, we transform the data to cuda.</span></span><br><span class="line">               <span class="keyword">if</span> use_gpu:</span><br><span class="line">                   inputs = Variable(inputs.cuda())</span><br><span class="line">                   labels = Variable(labels.cuda())</span><br><span class="line">               <span class="keyword">else</span>:</span><br><span class="line">                   inputs, labels = Variable(inputs), Variable(labels)</span><br><span class="line"></span><br><span class="line">               <span class="comment"># zero the parameter gradients</span></span><br><span class="line">               optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">               <span class="comment">#-------- forward --------</span></span><br><span class="line">               outputs = model(inputs)</span><br><span class="line">               _, preds = torch.max(outputs.data, <span class="number">1</span>)</span><br><span class="line">               loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">               <span class="comment">#-------- backward + optimize --------</span></span><br><span class="line">               <span class="comment"># only if in training phase</span></span><br><span class="line">               <span class="keyword">if</span> phase == <span class="string">'train'</span>:</span><br><span class="line">                   loss.backward()</span><br><span class="line">                   optimizer.step()</span><br></pre></td></tr></table></figure>

<p>每十轮，都会保存网络和更新loss曲线：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> epoch%<span class="number">10</span> == <span class="number">9</span>:</span><br><span class="line">                   save_network(model, epoch)</span><br><span class="line">               draw_curve(epoch)</span><br></pre></td></tr></table></figure>

<p>更多细节见train.py</p>
<p><strong>没有N卡的我流下了贫穷的眼泪23333</strong><br><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/ZM1SPJ6M7b*VbNYLqsE6ORqrK8W2TonTK7B6fGe3B5E!/b/dL8AAAAAAAAA&bo=jgMQAgAAAAADB70!&rf=viewer_4&t=5" alt></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/08/22/行人重识别代码实战（一）/">行人重识别代码实战（一）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-08-22</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/深度学习/">深度学习</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/行人重识别/">行人重识别</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/深度学习/">深度学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/图像处理/">图像处理</a></span><div class="content"><script src="/assets/js/APlayer.min.js"> </script><h1 id="代码描述"><a href="#代码描述" class="headerlink" title="代码描述"></a><strong>代码描述</strong></h1><p><strong>代码来源：</strong> <a href="https://github.com/layumi/Person_reID_baseline_pytorch" target="_blank" rel="noopener">https://github.com/layumi/Person_reID_baseline_pytorch</a></p>
<p><code>详细信息可见README.md</code></p>
<h1 id="prepare-py-文件简单讲解"><a href="#prepare-py-文件简单讲解" class="headerlink" title="prepare.py 文件简单讲解"></a>prepare.py 文件简单讲解</h1><p><strong>文件代码：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> shutil <span class="keyword">import</span> copyfile</span><br><span class="line"></span><br><span class="line"><span class="comment"># You only need to change this line to your dataset download path</span></span><br><span class="line">download_path = <span class="string">'C:/Users/葛宇/学习/ReId/数据集/Market-1501-v15.09.15'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(download_path):</span><br><span class="line">    print(<span class="string">'please change the download_path'</span>)</span><br><span class="line"></span><br><span class="line">save_path = download_path + <span class="string">'/pytorch'</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(save_path):</span><br><span class="line">    os.mkdir(save_path)</span><br><span class="line"><span class="comment">#-----------------------------------------</span></span><br><span class="line"><span class="comment">#query</span></span><br><span class="line">query_path = download_path + <span class="string">'/query'</span></span><br><span class="line">query_save_path = download_path + <span class="string">'/pytorch/query'</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(query_save_path):</span><br><span class="line">    os.mkdir(query_save_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(query_path, topdown=<span class="literal">True</span>):</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> files:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> name[<span class="number">-3</span>:]==<span class="string">'jpg'</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        ID  = name.split(<span class="string">'_'</span>)</span><br><span class="line">        src_path = query_path + <span class="string">'/'</span> + name</span><br><span class="line">        dst_path = query_save_path + <span class="string">'/'</span> + ID[<span class="number">0</span>] </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(dst_path):</span><br><span class="line">            os.mkdir(dst_path)</span><br><span class="line">        copyfile(src_path, dst_path + <span class="string">'/'</span> + name)</span><br><span class="line"></span><br><span class="line"><span class="comment">#-----------------------------------------</span></span><br><span class="line"><span class="comment">#multi-query</span></span><br><span class="line">query_path = download_path + <span class="string">'/gt_bbox'</span></span><br><span class="line"><span class="comment"># for dukemtmc-reid, we do not need multi-query</span></span><br><span class="line"><span class="keyword">if</span> os.path.isdir(query_path):</span><br><span class="line">    query_save_path = download_path + <span class="string">'/pytorch/multi-query'</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(query_save_path):</span><br><span class="line">        os.mkdir(query_save_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(query_path, topdown=<span class="literal">True</span>):</span><br><span class="line">        <span class="keyword">for</span> name <span class="keyword">in</span> files:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> name[<span class="number">-3</span>:]==<span class="string">'jpg'</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            ID  = name.split(<span class="string">'_'</span>)</span><br><span class="line">            src_path = query_path + <span class="string">'/'</span> + name</span><br><span class="line">            dst_path = query_save_path + <span class="string">'/'</span> + ID[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(dst_path):</span><br><span class="line">                os.mkdir(dst_path)</span><br><span class="line">            copyfile(src_path, dst_path + <span class="string">'/'</span> + name)</span><br><span class="line"></span><br><span class="line"><span class="comment">#-----------------------------------------</span></span><br><span class="line"><span class="comment">#gallery</span></span><br><span class="line">gallery_path = download_path + <span class="string">'/bounding_box_test'</span></span><br><span class="line">gallery_save_path = download_path + <span class="string">'/pytorch/gallery'</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(gallery_save_path):</span><br><span class="line">    os.mkdir(gallery_save_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(gallery_path, topdown=<span class="literal">True</span>):</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> files:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> name[<span class="number">-3</span>:]==<span class="string">'jpg'</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        ID  = name.split(<span class="string">'_'</span>)</span><br><span class="line">        src_path = gallery_path + <span class="string">'/'</span> + name</span><br><span class="line">        dst_path = gallery_save_path + <span class="string">'/'</span> + ID[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(dst_path):</span><br><span class="line">            os.mkdir(dst_path)</span><br><span class="line">        copyfile(src_path, dst_path + <span class="string">'/'</span> + name)</span><br><span class="line"></span><br><span class="line"><span class="comment">#---------------------------------------</span></span><br><span class="line"><span class="comment">#train_all</span></span><br><span class="line">train_path = download_path + <span class="string">'/bounding_box_train'</span></span><br><span class="line">train_save_path = download_path + <span class="string">'/pytorch/train_all'</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(train_save_path):</span><br><span class="line">    os.mkdir(train_save_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(train_path, topdown=<span class="literal">True</span>):</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> files:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> name[<span class="number">-3</span>:]==<span class="string">'jpg'</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        ID  = name.split(<span class="string">'_'</span>)</span><br><span class="line">        src_path = train_path + <span class="string">'/'</span> + name</span><br><span class="line">        dst_path = train_save_path + <span class="string">'/'</span> + ID[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(dst_path):</span><br><span class="line">            os.mkdir(dst_path)</span><br><span class="line">        copyfile(src_path, dst_path + <span class="string">'/'</span> + name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#---------------------------------------</span></span><br><span class="line"><span class="comment">#train_val</span></span><br><span class="line">train_path = download_path + <span class="string">'/bounding_box_train'</span></span><br><span class="line">train_save_path = download_path + <span class="string">'/pytorch/train'</span></span><br><span class="line">val_save_path = download_path + <span class="string">'/pytorch/val'</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(train_save_path):</span><br><span class="line">    os.mkdir(train_save_path)</span><br><span class="line">    os.mkdir(val_save_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(train_path, topdown=<span class="literal">True</span>):</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> files:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> name[<span class="number">-3</span>:]==<span class="string">'jpg'</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        ID  = name.split(<span class="string">'_'</span>)</span><br><span class="line">        src_path = train_path + <span class="string">'/'</span> + name</span><br><span class="line">        dst_path = train_save_path + <span class="string">'/'</span> + ID[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(dst_path):</span><br><span class="line">            os.mkdir(dst_path)</span><br><span class="line">            dst_path = val_save_path + <span class="string">'/'</span> + ID[<span class="number">0</span>]  <span class="comment">#first image is used as val image</span></span><br><span class="line">            os.mkdir(dst_path)</span><br><span class="line">        copyfile(src_path, dst_path + <span class="string">'/'</span> + name)</span><br></pre></td></tr></table></figure>

<p><strong>代码比较冗长，我总结一下。</strong><br>这个脚本的作用是将原始数据集重新按图片ID分类。主要操作是通过调用系统函数加之必要的循环判断来实现。可不必细究。运行之前先将第五行<code>download_path = &#39;C:/Users/葛宇/学习/ReId/数据集/Market-1501-v15.09.15&#39;</code>改为你自己的地址。<br>按照原作者的使用教程，第一步要做的就是运行prepare.py文件。<br>运行之后会发现在原先的Market1501数据集中（详见之前的博客）多出了一个文件夹“pytorch”,打开看看：</p>
<p><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/XOTpm6G*RPqW9HS2rDbz7NqYcu.o7Nzzy6zolYaKuR4!/b/dL8AAAAAAAAA&bo=xgE.AQAAAAADB9o!&rf=viewer_4&t=5" alt></p>
<p>里面是6个文件夹：</p>
<ol>
<li>gallery中包含752个文件夹项目，均按ID排序：<img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/WbJhKhBQTNXsAzx7dDwwdNzNTyTh0b4fI2hABj7oMAs!/b/dLYAAAAAAAAA&bo=tAHvAAAAAAADB3g!&rf=viewer_4&t=5" alt></li>
<li>multi中是1051个文件夹项目，从0001到1501</li>
<li>query中包含750个文件项目，不含0000和-1</li>
<li>train中包含751个文件项目，不含0000和-1</li>
<li>train all中包含751个文件项目，不含0000和-1</li>
<li>val中包含751个文件项目，不含0000和-1</li>
</ol>
<p>具体情况可以自己尝试打开观察。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/08/21/论文笔记（一）/">论文笔记（一）</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-08-21</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/论文笔记/">论文笔记</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/行人重识别/">行人重识别</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/深度学习/">深度学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/图像处理/">图像处理</a></span><div class="content"><script src="/assets/js/APlayer.min.js"> </script><p><strong>CVPR2017</strong></p>
<h1 id="Re-ranking-Person-Re-identification-with-k-reciprocal-Encoding"><a href="#Re-ranking-Person-Re-identification-with-k-reciprocal-Encoding" class="headerlink" title="Re-ranking Person Re-identification with k-reciprocal Encoding"></a><strong>Re-ranking Person Re-identification with k-reciprocal Encoding</strong></h1><p><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/quthbPxSeyjHta9ryFLzDIGAqnDAPhN.eqO1zVistSY!/b/dL4AAAAAAAAA&bo=3gWGAQAAAAADF24!&rf=viewer_4&t=5" alt></p>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>当将person re-ID看作一个检索过程时，re-ranking是提高其准确性的关键步骤。然而，在re-ID社区中，对re-ranking的努力有限，尤其是那些全自动、无监督的解决方案。在本文中，我们提出了一种k-reciprocal编码方法来re-ranking re-ID的结果。我们的假设是，如果一个gallery图像与k-reciprocal nearest neighbors中的probe查询相似，则更有可能是真正的匹配。具体地，给定图像，通过将其k-reciprocal nearest neighbors编码为单个向量来计算k-reciprocal特征，该向量用于在杰卡德距离（Jaccard Distance：用来衡量两个集合差异性的一种指标）下re-ranking。最终的距离计算为原始距离和杰卡德距离的组合。我们的re-ranking方法不需要任何人工交互或任何标记数据，因此适用于大规模数据集。在大型Market-1501、CUHK03、MARS和PRW数据集上的实验证实了我们方法的有效性。</p>
<hr>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>person re-ID是计算机视觉中的一个具有挑战性的课题。一般来说，re-ID可以被看作是一个检索问题。给定一个probe person，我们希望在gallery中搜索包含处于跨相机模式下的相同行人的图像。在获得初始排序列表之后，好的实践包括添加re-ranking步骤，期望相关图像将获得更高的排名。因此，本文将重点放在re-ranking问题上。</p>
<p>re-ranking主要是在通用实例检索generic instance retrieval[5、14、34、35]中进行研究。许多re-ranking主方法的主要优点是它可以在不需要额外训练样本的情况下实现，并且可以应用于任何初始ranking结果。</p>
<p>re-ranking的有效性在很大程度上取决于初始ranking列表initial ranking list的质量。许多先前的工作利用了初始排序列表[5，14，34，35，43，44]中排名靠前的图像(例如k-最近邻，k-nearest neighbors)之间的相似关系。一个基本的假设是，如果返回的图像在probe的k个最近邻内排序，那么它很可能是一个真正的匹配，可用于随后的re-ranking。然而，情况可能偏离最佳情况：错误匹配很可能包括在probe的k个最近邻中。例如，在图1中，P1、P2、P3和P4是4个查询图probe的真实匹配，但是它们都不包括在top-4中。我们观察到一些错误匹配（N1-N6）获得高排名。结果，直接使用top-k的图像可能在re-ranking系统中引入噪声并损害最终结果。<br><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/MHHGo3PiFcPGV.heCZ5g*b9oCnKigedSYRZacRKgEQ4!/b/dLgAAAAAAAAA&bo=egM2AwAAAAADB24!&rf=viewer_4&t=5" alt><br>在文献中，k-reciprocal nearest neighbor[14，34]是解决上述问题的有效方法，即被错误匹配污染的top-k图像。当两个图像被称为k-reciprocal nearest neighbor时，当另一个图像作为probe时，它们都被排到top-k。因此，k-reciprocal nearest neighbor作为两个图像是否正确匹配的更严格规则。在图1中，我们观察到probe是正确匹配图像的reciprocal neighbor，而不是错误匹配图像的reciprocal neighbor。该观察识别初始排序列表initial ranking list中的正确匹配，以改善重新排序re-ranking结果。</p>
<p>基于以上考虑，本文提出了一种基于k-reciprocal编码的re-ID re-ranking方法。我们的方法包括三个步骤。首先，将加权的k-reciprocal neighbor 集编码为一个向量，形成k-reciprocal特征。然后，两个图像之间的Jaccard距离可以通过它们的k-reciprocal特征来计算。其次，为了获得更鲁棒的k-reciprocal特征，我们改进了一种局部查询扩展方法（a local query expansion approach），以进一步改善re-ID性能。最后，最终距离的计算为原始距离和Jaccard距离的加权集合。随后，它被用来获取re-ranking列表。所提出的方法的框架如图2所示。综上所述，本文的贡献是：</p>
<ol>
<li>我们提出了一个k-reciprocal特征通过编码k-reciprocal特征到一个单一的向量。重re-ranking过程可以很容易地通过向量比较来执行。</li>
<li>我们的方法不需要任何人工交互或带标注的数据，并且可以自动和无监督的方式应用于任何人person re-ID ranking结果。</li>
<li>该方法有效地提高了Market-1501、CUHK03、MARS和PRW等数据集上的person re-ID性能。特别地，我们在rank-1和mAP上实现了Market-1501的最先进的精度。<br><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/0DItUXV9pF2lgTu1Y.aKgC6kqLkGsS0JiWXFbD1ch5Q!/b/dLgAAAAAAAAA&bo=sgWmAgAAAAADBzE!&rf=viewer_4&t=5" alt></li>
</ol>
<h1 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h1><p>我们推荐感兴趣的读者阅读[3，50]以详细回顾person re-ID。在此，我们重点研究用于目标检索，特别是用于re-ID的re-ranking方法。</p>
<p><strong>Re-ranking for object retrieval.</strong><br>Re-ranking方法已被成功地研究以提高目标检索精度[51]。许多工作利用k-nearest neighbors来探索相似关系来解决re-ranking问题。[5]提出了average query expansion (AQE)方法，该方法通过对top-k返回结果中的向量进行平均，得到一个新的查询向量（query vector），用于对数据库进行重新查询。为了利用远离查询图像的负样本，Arandjelović和Zisserman[1]改进了discriminative query expansion (DQE)，使用线性SVM来获得权重向量。从决策边界的距离被用来修改初始排序表（initial ranking list）。[35]利用初始排序表的k-nearest neighbors作为新查询（queries）来生成新的排序表。每个图像的新得分根据其在产生的排序表中的位置来计算。最近，稀疏上下文激活sparse contextual activation (SCA)[2]提出将neighbor set编码为向量，并通过广义Jaccard距离来表示样本的相似性。为了防止错误匹配对top-k图像的污染，[14，34]中采用了k-reciprocal nearest neighbors的概念。在[14]中提出了上下文不相似性度量contextual dissimilarity measure (CDM)，通过迭代正则化每个点到其邻域的平均距离来细化相似性。[34]正式提出k-reciprocal nearest neighbors的概念。k-reciprocal nearest neighbors被认为是高度相关的候选，用于构造闭集（closed set）以re-ranking数据集的其余部分。我们的工作从两个方面背离了这两个方法。我们不像文献[14]那样对最近邻（nearest neighborhood）关系进行对称化来细化相似度，也不像文献[34]那样直接将k-reciprocal nearest neighbors看作高阶样本。相反，我们通过比较两幅图像的k-reciprocal nearest neighbors来计算它们之间的新距离。</p>
<p><strong>Re-ranking for re-ID.</strong><br>大多数现有的person re-ID方法主要集中于特征表示[41，12，23，48，21]或度量学习[23，17，9，32，45]。最近，一些研究者[10，33，28，24，49，20，11，19，42，44]已经注意到在re-ID社区中基于re-ranking的方法。[20]通过分析每对图像的近邻（near neighbors）的相关信息和直接信息，建立re-ranking模型。在[11]中，通过联合考虑排序列表中的内容和上下文信息，学习无监督的重新排序模型，有效地去除了模糊样本，提高了re-ID的性能。[19]提出一种双向排序（bidirectional ranking）方法，利用计算得到的新相似度作为内容相似度和上下文相似度的融合，对初始排序表进行修正。最近，利用不同基线（different baseline）方法的公共最近邻来re-ranking任务[42，44]。[42]将全局特征和局部特征的公共最近邻作为新查询（queries），通过集合全局特征和局部特征的新排序列表来修改初始排序列表。在[44]中，利用k-nearest neighbor set从不同的baseline方法计算相似度和不相似度，然后进行相似度和不相似度的集合来优化初始排序表。上述方法在re-ranking方面继续取得进展，有望为将来从k-nearest neighbors发现进一步的信息作出贡献。然而，使用k-nearest neighbors直接实现re-ranking可能限制整体性能，因为常常包括错误匹配。<strong>为了解决这个问题，本文研究了k-reciprocal neighbors在person re-ID中的重要性，从而设计了一个简单而有效的re-ranking方法。</strong></p>
<h1 id="Proposed-Approach"><a href="#Proposed-Approach" class="headerlink" title="Proposed Approach"></a>Proposed Approach</h1><h3 id="Problem-Definition"><a href="#Problem-Definition" class="headerlink" title="Problem Definition"></a>Problem Definition</h3><p>给定查询图像<code>p</code>和<code>gallery set</code>（包含N幅图像，<code>G = {gi | i = 1, 2, ...N }</code>），<code>p</code>和<code>gi</code>之间的原始距离可以用马氏距离（Mahalanobis distance）衡量：<br><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/LafFutvYgClOX.l5p*4ZCLJYrsc5kjGmnVe24AzhgZU!/b/dL8AAAAAAAAA&bo=SAEkAAAAAAADB08!&rf=viewer_4&t=5" alt><br>其中，<code>xp</code>个<code>xg</code>分别代表查询图<code>p</code>和<strong>检测集gallery</strong>中<code>gi</code>的外观特征，<code>M</code>是半正定矩阵。<br>初始排序表：<br><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/*CHieJYsi9e4hpW5Nzt7eIBANq3UnJadUiHf3BdOurY!/b/dFABAAAAAAAA&bo=9AAgAAAAAAADB*Y!&rf=viewer_4&t=5" alt><br>可根据<code>probe p</code>和<code>gallery gi</code>之间的成对原始距离得到，其中：<br><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/1ITYBDPyVKddCU5YHyU7rkLxdqts.mdln6hRc3GanII!/b/dFQBAAAAAAAA&bo=wgAeAAAAAAADB*4!&rf=viewer_4&t=5" alt><br>我们的目标是对<code>L(p,G)</code>进行<strong>re-rank</strong>，使更多的正样本排在<code>top</code>列表中，从而提高person re-ID的性能。</p>
<h3 id="K-reciprocal-Nearest-Neighbors"><a href="#K-reciprocal-Nearest-Neighbors" class="headerlink" title="K -reciprocal Nearest Neighbors"></a>K -reciprocal Nearest Neighbors</h3><p>我们将<code>N(p,k)</code>定义为一个probe p的k-nearest neighbors（i.e. 排序列表的top-k samples）：<br><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/oJogkkZH0yToHQHSTx76.s7nQ1x85KKBW*DYwhLQVpg!/b/dL4AAAAAAAAA&bo=cwEgAAAAAAADB3A!&rf=viewer_4&t=5" alt><br>其中，<code>|.|</code>表示集合中候选的数目。k-reciprocal nearest neighbors <code>R(p, k)</code>可以定义为：<br><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/elNb3jUmT.dl72uC1o8RfZsJWJTD2dd1zyjrPbxq**0!/b/dL4AAAAAAAAA&bo=mgEdAAAAAAADB6Q!&rf=viewer_4&t=5" alt><br><strong>根据前面的描述，k-reciprocal nearest neighbors比k-nearest neighbors和probe p更相关</strong>。然而，由于照明、姿态、视图和遮挡的变化，正样本图像可能被从k-nearest neighbors中排除，并且随后不被包括在k-reciprocal nearest neighbors中。为了解决这个问题，我们根据以下条件将<code>R(p，k)</code>中每个候选项的<code>1/2 k-reciprocal nearest neighbors</code>增量地添加到更鲁棒的集合<code>R*(p，k)</code>中：<br><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/o8K2qkC14YoSKex4sy7y37h1TMGGO8RdyObH6*nZEaI!/b/dLgAAAAAAAAA&bo=fwGGAAAAAAADB9o!&rf=viewer_4&t=5" alt></p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>在本文中，我们解决person re-ID的re-ranking问题。通过将k-reciprocal nearest neighbors编码为单个向量，我们提出了k-reciprocal特征，从而可以通过向量比较容易地执行re-ranking过程。为了从相似样本中获取相似关系，提出了局部扩展查询（local expansion query）以获得更鲁棒的k-reciprocal特征。基于原始距离和Jaccard距离的组合的最终距离有效地提高了多个大规模数据集上的re-ID性能。值得一提的是，我们的方法是全自动和无监督的，并且可以很容易地实现任何ranking结果。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/07/31/行人重识别初识/">行人重识别初识</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-07-31</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/深度学习/">深度学习</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/行人重识别/">行人重识别</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/深度学习/">深度学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/图像处理/">图像处理</a></span><div class="content"><script src="/assets/js/APlayer.min.js"> </script><p><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/DrhJV*nxNYDylnn2NaZf2b8k2K6lWwJJnrp7eC32KUQ!/b/dDUBAAAAAAAA&bo=8QPeAgAAAAADBww!&rf=viewer_4&t=5" alt></p>
<h1 id="行人重识别是什么？"><a href="#行人重识别是什么？" class="headerlink" title="行人重识别是什么？"></a>行人重识别是什么？</h1><p><strong>行人重识别（Person re-identification）</strong>也称行人再识别，是利用计算机视觉技术判断图像或者视频序列中是否存在特定行人的技术。广泛被认为是一个图像检索的子问题。给定一个监控行人图像，检索跨设备下的该行人图像。旨在弥补目前固定的摄像头的视觉局限，并可与行人检测/行人跟踪技术相结合，可广泛应用于智能视频监控、智能安保等领域。由于不同摄像设备之间的差异，同时行人兼具刚性和柔性的特性 ，外观易受穿着、尺度、遮挡、姿态和视角等影响，使得行人重识别成为计算机视觉领域中一个既具有研究价值同时又极具挑战性的热门课题。</p>
<hr>
<h1 id="技术难点"><a href="#技术难点" class="headerlink" title="技术难点"></a>技术难点</h1><ul>
<li><p><strong>能不能用人脸识别做重识别？</strong><br>理论上是可以的。但是有两个原因导致人脸识别较难应用：首先，广泛存在后脑勺和侧脸的情况，做正脸的人脸识别难。其次，摄像头拍摄的像素可能不高，尤其是远景摄像头里面人脸截出来很可能都没有32x32的像素。所以人脸识别在实际的重识别应用中很可能有限。</p>
</li>
<li><p><strong>有些人靠衣服的颜色就可以判断出来了，还需要行人重识别么？</strong><br>衣服颜色确实是行人重识别做出判断一个重要因素，但光靠颜色是不足的。首先，摄像头之间是有色差，并且会有光照的影响。其次，有撞衫（颜色相似）的人怎么办，要找细节，但比如颜色直方图这种统计的特征就把细节给忽略了。在多个数据集上的测试表明，光用颜色特征是难以达到50%的top1正确率的。</p>
</li>
<li><p><strong>总结</strong>：</p>
</li>
</ul>
<ol>
<li>不同下摄像头造成行人外观的巨大变化；</li>
<li>目标遮挡（Occlusion）导致部分特征丢失；</li>
<li>不同的 View，Illumination 导致同一目标的特征差异；</li>
<li>不同目标衣服颜色近似、特征近似导致区分度下降；</li>
</ol>
<hr>
<h1 id="基本方法"><a href="#基本方法" class="headerlink" title="基本方法"></a>基本方法</h1><h2 id="基于部件匹配的方法"><a href="#基于部件匹配的方法" class="headerlink" title="基于部件匹配的方法"></a>基于部件匹配的方法</h2><p>** 基于人体在三维空间中的结构（结构信息），人体图像可以进行分割，按部件来执行匹配。**</p>
<ul>
<li>常见方案是水平切割，就是将图像切为几个水平的条。由于人体身材往往差不多，所以可以用简单的水平条来做一一比较。</li>
<li>在领域中做匹配，采用的是一个正方形的邻域。</li>
<li>另一个较新的方案是先在人体上检测部件（手，腿，躯干等等）再进行匹配，这样的话可以减少位置的误差，但可能引入检测部件的误差。</li>
<li>类似LSTM的attention匹配，但必须pair输入，测试时间较长，不适合快速图像检索。</li>
<li>如图，类似人脸对齐，使用STN 将行人整个图像先利用热度图对齐，再匹配。<br><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/ZUqniLGv1QMblxPK63SOcNe8PA*bJ*FL1hSDIsValD0!/b/dIMAAAAAAAAA&bo=tgPaAQAAAAADRww!&rf=viewer_4&t=5" alt><h2 id="基于损失函数的方法"><a href="#基于损失函数的方法" class="headerlink" title="基于损失函数的方法"></a>基于损失函数的方法</h2></li>
</ul>
<p><strong>基于高层语义信息，设置一些辅助任务，帮助模型学习到好的特征表达。</strong></p>
<ul>
<li>身份损失（Identification loss）直接拿身份label做多类分类。</li>
<li>鉴定损失（Verification loss）比较两个输入图像是否为同一人。</li>
<li>身份损失（Identification loss）+鉴定损失（Verification loss），将以上两种损失函数混合。</li>
<li>三样本损失 （Triplet loss） 以3个样本为一组，同一人的图像特征距离应小于不同人。</li>
<li>加入属性任务 （attribute）比如判断是否背包，是男生还是女生等等。人们遇见陌生人也是利用这些属性来描述。</li>
<li>数据增强 混合多数据集训练 ，加入训练集上 生成对抗网络（GAN）生成的数据，如图：<br><img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/9cgIR.eYpmHQhOq2QIowcH3Ai8H9QWEDy2v3OKvWA84!/b/dL8AAAAAAAAA&bo=JgXYAQAAAAADR5g!&rf=viewer_4&t=5" alt></li>
</ul>
<h1 id="识别机制"><a href="#识别机制" class="headerlink" title="识别机制"></a>识别机制</h1><p><strong>如图</strong><br> <img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/GBBD3083WJ9xnvJTIYdWGGva7hFpEOUVBqPMO6Jt6y4!/b/dFMBAAAAAAAA&bo=UQY.AgAAAAADB0k!&rf=viewer_4&t=5" alt><br>首先要做的是<strong>Detection</strong>，也就是检测出行人，其实这一步数据集已经帮我们做到了，下面介绍数据集的时候会讲到不同数据集采用的不同的目标检测方法以及ID的标注方式。剩下的部分，就是要去<strong>训练一个特征提取网络</strong>，根据特征所计算的度量距离得到损失值，我们选用一个优化器去迭代找到loss最小值，并不断更新网络的参数达到学习的效果。在测试的时候，我们用将要检索的图片（称为<strong>query</strong>或者<strong>probe</strong>），在<strong>底库gallery</strong>中，根据计算出的特征距离进行排序，选出最TOP的几张图片，来达到目标检索的目的。</p>
<p>下面两张图分别是<strong>训练阶段</strong>和<strong>测试阶段</strong>的示意图：<br> <img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/3u4ENa9kmZi31OzilqWvm63WTITAshrbcwiaKpP*XzU!/b/dD4BAAAAAAAA&bo=dwLjAAAAAAADB7Q!&rf=viewer_4&t=5" alt><br>** 训练阶段**<br>  <img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/DPgxyfRqYuaLPoOzkulTz*Qj.LTKtw8djbTIr8uVKL8!/b/dFIBAAAAAAAA&bo=GgMMAQAAAAADBzY!&rf=viewer_4&t=5" alt><br>**  测试阶段**</p>
<hr>
<h1 id="评测指标"><a href="#评测指标" class="headerlink" title="评测指标"></a>评测指标</h1><h2 id="rank-k"><a href="#rank-k" class="headerlink" title="rank-k"></a>rank-k</h2><p><code>算法返回的排序列表中，前k位为存在检索目标则称为rank-k命中</code><br><strong>举个例子:</strong><br>假如在人脸识别中，底库中有100个人，现在来了1个待识别的人脸（假如label为m1），与底库中的人脸比对后将底库中的人脸按照得分从高到低进行排序，我们发现：<br>如果识别结果是m1、m2、m3、m4、m5……，则此时rank-1的正确率为100%；rank-2的正确率也为100%；rank-5的正确率也为100%；<br>如果识别结果是m2、m1、m3、m4、m5……，则此时rank-1的正确率为0%；rank-2的正确率为100%；rank-5的正确率也为100%；<br>如果识别结果是m2、m3、m4、m5、m1……，则此时rank-1的正确率为0%；rank-2的正确率为0%；rank-5的正确率为100%；<br>同理，当待识别的人脸集合有很多时，则采取取平均值的做法。例如待识别人脸有3个（假如label为m1，m2，m3），同样对每一个人脸都有一个从高到低的得分，<br><strong>比如：</strong><br>人脸1结果为m1、m2、m3、m4、m5……，<br>人脸2结果为m2、m1、m3、m4、m5……，<br>人脸3结果m3、m1、m2、m4、m5……，<br>则此时rank-1的正确率为（1+1+1）/3=100%；<br>rank-2的正确率也为（1+1+1）/3=100%；<br>rank-5的正确率也为（1+1+1）/3=100%；<br><strong>比如：</strong><br>人脸1结果为m4、m2、m3、m5、m6……，<br>人脸2结果为m1、m2、m3、m4、m5……，<br>人脸3结果m3、m1、m2、m4、m5……，<br>则此时rank-1的正确率为（0+0+1）/3=33.33%；<br>rank-2的正确率为（0+1+1）/3=66.66%；<br>rank-5的正确率也为（0+1+1）/3=66.66%；</p>
<h2 id="mAP-mean-average-precision"><a href="#mAP-mean-average-precision" class="headerlink" title="mAP(mean average precision)"></a>mAP(mean average precision)</h2><p>反应检索的人在数据库中所有正确的图片排在排序列表前面的程度，能更加全面的衡量ReID算法的性能。如下图，假设该检索行人在gallery中有10张图片，在检索的list中位置（rank）分别为1、2、3、4、5、6、7、8、9，则ap为(1/ 1 + 2 / 2 + 3 / 3 + 4 / 4 + 5 / 5 + 6 / 6 + 7 / 7 + 8 / 8 + 9 / 9) / 10 = 0.90；ap较大时，该行人的检索结果都相对靠前，对所有query的ap取平均值得到mAP<br> <img src="http://m.qpic.cn/psb?/V14eJTFY137vJk/zW4mb6uUdYdZiz96xyG9m0rGuuQ6*83516KdXH5y1DI!/b/dL8AAAAAAAAA&bo=fgU5AQAAAAADB2E!&rf=viewer_4&t=5" alt></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/07/31/Person Re-identification数据集描述——Market-1501/">Person Re-identification数据集描述——Market-1501</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-07-31</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/数据集/">数据集</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/数据集/">数据集</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/行人重识别/">行人重识别</a></span><div class="content"><script src="/assets/js/APlayer.min.js"> </script><p><img src="http://changingfond.oss-cn-hangzhou.aliyuncs.com/18-7-12/87140649.jpg" alt></p>
<h1 id="数据集简介"><a href="#数据集简介" class="headerlink" title="数据集简介"></a>数据集简介</h1><p><strong>Market-1501</strong> 数据集在清华大学校园中采集，夏天拍摄，在 2015 年构建并公开。它包括由6个摄像头（其中5个高清摄像头和1个低清摄像头）拍摄到的 1501 个行人、32668 个检测到的行人矩形框。每个行人至少由2个摄像头捕获到，并且在一个摄像头中可能具有多张图像。训练集有 751 人，包含 12,936 张图像，平均每个人有 17.2 张训练数据；测试集有 750 人，包含 19,732 张图像，平均每个人有 26.3 张测试数据。3368 张查询图像的行人检测矩形框是人工绘制的，而 gallery 中的行人检测矩形框则是使用DPM检测器检测得到的。该数据集提供的固定数量的训练集和测试集均可以在single-shot或multi-shot测试设置下使用。</p>
<h2 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h2><p>Market-1501<br>　　├── bounding_box_test<br>　　　　　　　├── 0000_c1s1_000151_01.jpg<br>　　　　　　　├── 0000_c1s1_000376_03.jpg<br>　　　　　　　├── 0000_c1s1_001051_02.jpg<br>　　├── bounding_box_train<br>　　　　　　　├── 0002_c1s1_000451_03.jpg<br>　　　　　　　├── 0002_c1s1_000551_01.jpg<br>　　　　　　　├── 0002_c1s1_000801_01.jpg<br>　　├── gt_bbox<br>　　　　　　　├── 0001_c1s1_001051_00.jpg<br>　　　　　　　├── 0001_c1s1_009376_00.jpg<br>　　　　　　　├── 0001_c2s1_001976_00.jpg<br>　　├── gt_query<br>　　　　　　　├── 0001_c1s1_001051_00_good.mat<br>　　　　　　　├── 0001_c1s1_001051_00_junk.mat<br>　　├── query<br>　　　　　　　├── 0001_c1s1_001051_00.jpg<br>　　　　　　　├── 0001_c2s1_000301_00.jpg<br>　　　　　　　├── 0001_c3s1_000551_00.jpg<br>　　└── readme.txt</p>
<h2 id="目录介绍"><a href="#目录介绍" class="headerlink" title="目录介绍"></a>目录介绍</h2><ul>
<li><strong>“bounding_box_test”</strong>——用于测试集的 750 人，包含 19,732 张图像，前缀为 0000 表示在提取这 750 人的过程中DPM检测错的图（可能与query是同一个人），-1 表示检测出来其他人的图（不在这 750 人中）</li>
</ul>
<ul>
<li><p><strong>“bounding_box_train”</strong>——用于训练集的 751 人，包含 12,936 张图像</p>
</li>
<li><p><strong>“query”</strong>——为 750 人在每个摄像头中随机选择一张图像作为query，因此一个人的query最多有 6 个，共有 3,368 张图像</p>
</li>
<li><p><strong>“gt_query”</strong>——matlab格式，用于判断一个query的哪些图片是好的匹配（同一个人不同摄像头的图像）和不好的匹配（同一个人同一个摄像头的图像或非同一个人的图像）</p>
</li>
<li><p><strong>“gt_bbox”</strong>——手工标注的bounding box，用于判断DPM检测的bounding box是不是一个好的box</p>
</li>
</ul>
<h2 id="命名规则"><a href="#命名规则" class="headerlink" title="命名规则"></a>命名规则</h2><p><strong>以 0001_c1s1_000151_01.jpg 为例</strong></p>
<ul>
<li>0001 表示每个人的标签编号，从0001到1501；</li>
<li>c1 表示第一个摄像头(camera1)，共有6个摄像头；</li>
<li>s1 表示第一个录像片段(sequece1)，每个摄像机都有数个录像段；</li>
<li>000151 表示 c1s1 的第000151帧图片，视频帧率25fps；</li>
<li>01 表示 c1s1_001051 这一帧上的第1个检测框，由于采用DPM检测器，对于每一帧上的行人可能会框出好几个bbox。00 表示手工标注框</li>
</ul>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li>Zheng, Liang, et al. “Scalable Person Re-identification: A Benchmark.” IEEE International Conference on Computer Vision IEEE Computer Society, 2015:1116-1124.</li>
</ul>
</div><hr></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fa fa-chevron-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(http://a1.qpic.cn/psb?/V14eJTFY137vJk/i09jWCouwvJawAtXHQ7*VnrLqAAatJunqVGTTh85alU!/b/dNwAAAAAAAAA&amp;ek=1&amp;kp=1&amp;pt=0&amp;bo=HAtABgAPcAgRGQg!&amp;tl=3&amp;vuin=1328447669&amp;tm=1562745600&amp;sce=60-2-2&amp;rf=viewer_4&amp;t=5)"><div class="layout" id="footer"><div class="copyright">&copy;2015 - 2020 By GeYu</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">Enjoy the cyber world!</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>